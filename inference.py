#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ»‘å—éªŒè¯ç æ¨ç†è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„YOLOv5æ¨¡å‹è¯†åˆ«æ»‘å—éªŒè¯ç ä¸­çš„ç¼ºå£ä½ç½®
"""

import torch
import cv2
import numpy as np
from pathlib import Path
import argparse
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class SliderCaptchaDetector:
    def __init__(self, model_path, device='cpu'):
        """
        åˆå§‹åŒ–æ»‘å—éªŒè¯ç æ£€æµ‹å™¨
        
        Args:
            model_path: è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt)
            device: æ¨ç†è®¾å¤‡ ('cpu' æˆ– 'cuda')
        """
        self.device = device
        self.model = self.load_model(model_path)
        
    def load_model(self, model_path):
        """åŠ è½½YOLOv5æ¨¡å‹"""
        if not Path(model_path).exists():
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
        print(f"ğŸ“¦ åŠ è½½æ¨¡å‹: {model_path}")
        
        # ä½¿ç”¨ultralytics YOLOç±»åŠ è½½è‡ªå®šä¹‰æ¨¡å‹
        from ultralytics import YOLO
        model = YOLO(model_path)
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {self.device}")
        return model
    
    def detect(self, image_path, conf_threshold=0.5):
        """
        æ£€æµ‹æ»‘å—éªŒè¯ç ä¸­çš„ç¼ºå£ä½ç½®
        
        Args:
            image_path: éªŒè¯ç å›¾ç‰‡è·¯å¾„
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            
        Returns:
            dict: æ£€æµ‹ç»“æœ {x, y, width, height, confidence}
        """
        if not Path(image_path).exists():
            raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
        # åŠ è½½å›¾ç‰‡
        image = Image.open(image_path)
        original_size = image.size
        
        print(f"ğŸ” æ£€æµ‹å›¾ç‰‡: {image_path}")
        print(f"ğŸ“ å›¾ç‰‡å°ºå¯¸: {original_size}")
        
        # YOLOv5æ¨ç†
        results = self.model(image)
        
        # è§£æç»“æœ
        detections = results.pandas().xyxy[0]  # è·å–pandasæ ¼å¼ç»“æœ
        
        if len(detections) == 0:
            print("âŒ æœªæ£€æµ‹åˆ°æ»‘å—ç¼ºå£")
            return None
            
        # è·å–ç½®ä¿¡åº¦æœ€é«˜çš„æ£€æµ‹ç»“æœ
        best_detection = detections.loc[detections['confidence'].idxmax()]
        
        if best_detection['confidence'] < conf_threshold:
            print(f"âš ï¸  æ£€æµ‹ç½®ä¿¡åº¦è¿‡ä½: {best_detection['confidence']:.3f}")
            return None
            
        # æå–è¾¹ç•Œæ¡†ä¿¡æ¯
        result = {
            'x': int(best_detection['xmin']),
            'y': int(best_detection['ymin']),
            'width': int(best_detection['xmax'] - best_detection['xmin']),
            'height': int(best_detection['ymax'] - best_detection['ymin']),
            'confidence': float(best_detection['confidence']),
            'center_x': int((best_detection['xmin'] + best_detection['xmax']) / 2),
            'center_y': int((best_detection['ymin'] + best_detection['ymax']) / 2)
        }
        
        print(f"âœ… æ£€æµ‹æˆåŠŸ!")
        print(f"ğŸ“ ç¼ºå£ä½ç½®: ({result['x']}, {result['y']})")
        print(f"ğŸ“ ç¼ºå£å°ºå¯¸: {result['width']} x {result['height']}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {result['confidence']:.3f}")
        print(f"ğŸ¯ ä¸­å¿ƒç‚¹: ({result['center_x']}, {result['center_y']})")
        
        return result
    
    def visualize_detection(self, image_path, detection_result, save_path=None):
        """
        å¯è§†åŒ–æ£€æµ‹ç»“æœ
        
        Args:
            image_path: åŸå›¾è·¯å¾„
            detection_result: æ£€æµ‹ç»“æœ
            save_path: ä¿å­˜è·¯å¾„ (å¯é€‰)
        """
        if detection_result is None:
            print("âŒ æ— æ£€æµ‹ç»“æœå¯è§†åŒ–")
            return
            
        # åŠ è½½å›¾ç‰‡
        image = Image.open(image_path)
        
        # åˆ›å»ºmatplotlibå›¾å½¢
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        ax.imshow(image)
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†
        rect = patches.Rectangle(
            (detection_result['x'], detection_result['y']),
            detection_result['width'], detection_result['height'],
            linewidth=3, edgecolor='red', facecolor='none'
        )
        ax.add_patch(rect)
        
        # ç»˜åˆ¶ä¸­å¿ƒç‚¹
        ax.plot(detection_result['center_x'], detection_result['center_y'], 
               'ro', markersize=8)
        
        # æ·»åŠ æ ‡ç­¾
        label = f"æ»‘å—ç¼ºå£\nç½®ä¿¡åº¦: {detection_result['confidence']:.3f}\n" \
                f"ä½ç½®: ({detection_result['x']}, {detection_result['y']})\n" \
                f"ä¸­å¿ƒ: ({detection_result['center_x']}, {detection_result['center_y']})"
        
        ax.text(detection_result['x'], detection_result['y'] - 10, label,
               bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.8),
               fontsize=10, color='black')
        
        ax.set_title('æ»‘å—éªŒè¯ç ç¼ºå£æ£€æµ‹ç»“æœ', fontsize=16, fontweight='bold')
        ax.axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ å¯è§†åŒ–ç»“æœä¿å­˜åˆ°: {save_path}")
        
        plt.show()

def main():
    parser = argparse.ArgumentParser(description='æ»‘å—éªŒè¯ç æ¨ç†')
    parser.add_argument('--model', required=True,
                       help='è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„ (.pt)')
    parser.add_argument('--image', required=True,
                       help='å¾…æ£€æµ‹çš„éªŒè¯ç å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--conf', type=float, default=0.5,
                       help='ç½®ä¿¡åº¦é˜ˆå€¼ (é»˜è®¤: 0.5)')
    parser.add_argument('--device', default='cpu',
                       help='æ¨ç†è®¾å¤‡ (cpu/cuda)')
    parser.add_argument('--visualize', action='store_true',
                       help='æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ')
    parser.add_argument('--save-result', 
                       help='ä¿å­˜å¯è§†åŒ–ç»“æœçš„è·¯å¾„')
    
    args = parser.parse_args()
    
    print("ğŸ¯ æ»‘å—éªŒè¯ç æ¨ç†")
    print("=" * 50)
    
    try:
        # åˆ›å»ºæ£€æµ‹å™¨
        detector = SliderCaptchaDetector(
            model_path=args.model,
            device=args.device
        )
        
        # æ‰§è¡Œæ£€æµ‹
        result = detector.detect(
            image_path=args.image,
            conf_threshold=args.conf
        )
        
        # è¾“å‡ºç»“æœ
        if result:
            print("\nğŸ“Š æ£€æµ‹ç»“æœ:")
            print(f"  ç¼ºå£ä½ç½®: ({result['x']}, {result['y']})")
            print(f"  ç¼ºå£å°ºå¯¸: {result['width']} x {result['height']}")
            print(f"  ä¸­å¿ƒåæ ‡: ({result['center_x']}, {result['center_y']})")
            print(f"  ç½®ä¿¡åº¦: {result['confidence']:.3f}")
            
            # å¯è§†åŒ–
            if args.visualize or args.save_result:
                detector.visualize_detection(
                    args.image, result, args.save_result
                )
        else:
            print("âŒ æ£€æµ‹å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ æ¨ç†è¿‡ç¨‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main()
